{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependency packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 版本： 1.3.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch 版本：\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字典大小： 21128\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "\n",
    "vocab = tokenizer.vocab\n",
    "print(\"字典大小：\", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token               index          \n",
      "-------------------------\n",
      "##医                 14335\n",
      "瓯                    4484\n",
      "壶                    1901\n",
      "##赴                 19683\n",
      "面                    7481\n",
      "诺                    6437\n",
      "锂                    7220\n",
      "##啼                 14639\n",
      "庭                    2431\n",
      "傣                     994\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_tokens = random.sample(list(vocab), 10)\n",
    "random_ids = [vocab[i] for i in random_tokens]\n",
    "\n",
    "print(\"{0:20}{1:15}\".format(\"token\", \"index\"))\n",
    "print(\"-\" * 25)\n",
    "for token, index in zip(random_tokens, random_ids):\n",
    "    print(\"{0:15}{1:10}\".format(token, index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Predict missing word using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 你知道的，深度学习调参一个玄学 [MASK] 题。\n",
      "['[CLS]', '你', '知', '道', '的', '，', '深', '度', '学', '习', '调', '参', '一', '个', '玄', '学', '[MASK]', '题', '。']\n",
      "[101, 872, 4761, 6887, 4638, 8024, 3918, 2428, 2110, 739, 6444, 1346, 671, 702, 4371, 2110, 103, 7579, 511]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"[CLS] 你知道的，深度学习调参一个玄学 [MASK] 题。\"\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(sentence)\n",
    "print(tokens)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 版本： 1.3.1\n",
      "['[CLS]', '你', '知', '道', '的', '，', '深', '度', '学', '习', '调', '参', '一', '个', '玄', '学', '[MASK]', '题', '。']\n",
      "----------------------------------------------------------------\n",
      "Top 1 (70%)：['[CLS]', '你', '知', '道', '的', '，', '深', '度', '学', '习', '调', '参', '一', '个', '玄', '学', '问', '题', '。']\n",
      "Top 2 ( 6%)：['[CLS]', '你', '知', '道', '的', '，', '深', '度', '学', '习', '调', '参', '一', '个', '玄', '学', '难', '题', '。']\n",
      "Top 3 ( 5%)：['[CLS]', '你', '知', '道', '的', '，', '深', '度', '学', '习', '调', '参', '一', '个', '玄', '学', '话', '题', '。']\n",
      "Top 4 ( 3%)：['[CLS]', '你', '知', '道', '的', '，', '深', '度', '学', '习', '调', '参', '一', '个', '玄', '学', '课', '题', '。']\n",
      "Top 5 ( 3%)：['[CLS]', '你', '知', '道', '的', '，', '深', '度', '学', '习', '调', '参', '一', '个', '玄', '学', '主', '题', '。']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch 版本：\", torch.__version__)\n",
    "\n",
    "from transformers import BertForMaskedLM\n",
    "\n",
    "# Token tensor对应句子具体内容，segment tensor对应不同句子标识\n",
    "tokens_tensor = torch.tensor([ids])\n",
    "segments_tensors = torch.zeros_like(tokens_tensor)\n",
    "maskedLM_model = BertForMaskedLM.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "\n",
    "# 使用模型预测句子缺失内容\n",
    "maskedLM_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = maskedLM_model(tokens_tensor, segments_tensors)\n",
    "    predictions = outputs[0]\n",
    "    # (1, seq_len, num_hidden_units)\n",
    "\n",
    "# 提取出最有可能的前k个缺失内容\n",
    "masked_index = 16\n",
    "k = 5\n",
    "probs, indices = torch.topk(torch.softmax(predictions[0, masked_index], -1), k)\n",
    "predicted_tokens = tokenizer.convert_ids_to_tokens(indices.tolist())\n",
    "\n",
    "print(tokens)\n",
    "print('-' * 64)\n",
    "for i, (t, p) in enumerate(zip(predicted_tokens, probs), 1):\n",
    "    tokens[masked_index] = t\n",
    "    print(\"Top {} ({:2}%)：{}\".format(i, int(p.item() * 100), tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入需要进行填空的句子，其中缺失部分用空格代替：\n",
      "卖竹鼠了，三元一 ，十元三只。\n",
      "[CLS] 卖竹鼠了，三元一 [MASK] ，十元三只。\n",
      "----------------------------------------------------------------\n",
      "['[CLS]', '卖', '竹', '鼠', '了', '，', '三', '元', '一', '[MASK]', '，', '十', '元', '三', '只', '。']\n",
      "----------------------------------------------------------------\n",
      "Top 1 (93%)：['[CLS]', '卖', '竹', '鼠', '了', '，', '三', '元', '一', '只', '，', '十', '元', '三', '只', '。']\n",
      "Top 2 ( 1%)：['[CLS]', '卖', '竹', '鼠', '了', '，', '三', '元', '一', '个', '，', '十', '元', '三', '只', '。']\n",
      "Top 3 ( 0%)：['[CLS]', '卖', '竹', '鼠', '了', '，', '三', '元', '一', '双', '，', '十', '元', '三', '只', '。']\n",
      "\n",
      "继续？(Y/N)Y\n",
      "----------------------------------------------------------------\n",
      "请输入需要进行填空的句子，其中缺失部分用空格代替：\n",
      "以前 没得选，现在我想做个好人。\n",
      "[CLS] 以前 [MASK] 没得选，现在我想做个好人。\n",
      "----------------------------------------------------------------\n",
      "['[CLS]', '以', '前', '[MASK]', '没', '得', '选', '，', '现', '在', '我', '想', '做', '个', '好', '人', '。']\n",
      "----------------------------------------------------------------\n",
      "Top 1 (91%)：['[CLS]', '以', '前', '我', '没', '得', '选', '，', '现', '在', '我', '想', '做', '个', '好', '人', '。']\n",
      "Top 2 ( 1%)：['[CLS]', '以', '前', '你', '没', '得', '选', '，', '现', '在', '我', '想', '做', '个', '好', '人', '。']\n",
      "Top 3 ( 0%)：['[CLS]', '以', '前', '还', '没', '得', '选', '，', '现', '在', '我', '想', '做', '个', '好', '人', '。']\n",
      "\n",
      "继续？(Y/N)Y\n",
      "----------------------------------------------------------------\n",
      "请输入需要进行填空的句子，其中缺失部分用空格代替：\n",
      "这是最好的时代，也是最 的时代。\n",
      "[CLS] 这是最好的时代，也是最 [MASK] 的时代。\n",
      "----------------------------------------------------------------\n",
      "['[CLS]', '这', '是', '最', '好', '的', '时', '代', '，', '也', '是', '最', '[MASK]', '的', '时', '代', '。']\n",
      "----------------------------------------------------------------\n",
      "Top 1 (66%)：['[CLS]', '这', '是', '最', '好', '的', '时', '代', '，', '也', '是', '最', '坏', '的', '时', '代', '。']\n",
      "Top 2 (15%)：['[CLS]', '这', '是', '最', '好', '的', '时', '代', '，', '也', '是', '最', '好', '的', '时', '代', '。']\n",
      "Top 3 ( 3%)：['[CLS]', '这', '是', '最', '好', '的', '时', '代', '，', '也', '是', '最', '难', '的', '时', '代', '。']\n",
      "\n",
      "继续？(Y/N)N\n"
     ]
    }
   ],
   "source": [
    "test = True\n",
    "while(test):\n",
    "    sentence = input(\"请输入需要进行填空的句子，其中缺失部分用空格代替：\\n\")\n",
    "    masked_index = sentence.find(\" \") + 1\n",
    "    sentence = sentence.replace(\" \", \" [MASK] \")\n",
    "    sentence = \"[CLS] \" + sentence\n",
    "    print(sentence)\n",
    "    print('-' * 64)\n",
    "    \n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    tokens_tensor = torch.tensor([ids])\n",
    "    segments_tensors = torch.zeros_like(tokens_tensor)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = maskedLM_model(tokens_tensor, segments_tensors)\n",
    "        predictions = outputs[0]\n",
    "        \n",
    "    k = 3\n",
    "    probs, indices = torch.topk(torch.softmax(predictions[0, masked_index], -1), k)\n",
    "    predicted_tokens = tokenizer.convert_ids_to_tokens(indices.tolist())\n",
    "    \n",
    "    print(tokens)\n",
    "    print('-' * 64)\n",
    "    for i, (t, p) in enumerate(zip(predicted_tokens, probs), 1):\n",
    "        tokens[masked_index] = t\n",
    "        print(\"Top {} ({:2}%)：{}\".format(i, int(p.item() * 100), tokens))\n",
    "    \n",
    "    operation = input(\"\\n继续？(Y/N)\").lower()\n",
    "    if operation == \"yes\" or operation == \"y\":\n",
    "        print('-' * 64)\n",
    "    else:\n",
    "        test = False\n",
    "\n",
    "del maskedLM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
